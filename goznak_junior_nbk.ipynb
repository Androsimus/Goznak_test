{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuda device checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your device is \"cuda:0\"\n"
     ]
    }
   ],
   "source": [
    "device = ''\n",
    "if torch.cuda.is_available():  \n",
    "    device = \"cuda:0\" \n",
    "else:  \n",
    "    device = \"cpu\"\n",
    "print(f'Your device is \"{device}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings for reproducibility "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x217f9aed490>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(17)\n",
    "torch.manual_seed(13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data:\n",
    "## Define functions to \n",
    "  - load \n",
    "  - preprocess\n",
    "  - check input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((875, 80), (80, 875), (840, 80))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = np.load(r'data\\train1\\train\\clean\\20\\20_205_20-205-0004.npy')\n",
    "x2 = np.load(r'data\\train1\\train\\clean\\20\\20_205_20-205-0012.npy')\n",
    "x1.shape, x1.T.shape, x2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Form a list of directories which contain train or val samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1_path, val_path = 'data/train1/train/', 'data/val/val/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_data_paths(path: str):\n",
    "    \"\"\"\n",
    "    input: path to train or val dir with 'clean' and 'noise' dirs\n",
    "    output: list of paths to clean data\n",
    "    \"\"\"\n",
    "    clean = 'clean/'\n",
    "    list_clean = []\n",
    "    with os.scandir(path+clean) as entries:\n",
    "        for entry in entries:\n",
    "            if entry.is_dir():\n",
    "                list_clean.append(entry.path)\n",
    "    return sorted(list_clean)\n",
    "\n",
    "def check_data_paths(paths_list, show_cnt = 10):\n",
    "    \"\"\"\n",
    "    outputs number of input list elements and their values\n",
    "    \"\"\"\n",
    "    print(f'input list length = {len(paths_list)}')\n",
    "    for i, elem in enumerate(paths_list):\n",
    "        print(elem)\n",
    "        if i==show_cnt:\n",
    "            break\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input list length = 799\n",
      "data/train1/train/clean/1006\n",
      "data/train1/train/clean/102\n",
      "data/train1/train/clean/104\n",
      "data/train1/train/clean/1049\n",
      "data/train1/train/clean/1051\n",
      "data/train1/train/clean/1065\n",
      "data/train1/train/clean/107\n",
      "data/train1/train/clean/1085\n",
      "data/train1/train/clean/1092\n",
      "data/train1/train/clean/1094\n",
      "data/train1/train/clean/1097\n"
     ]
    }
   ],
   "source": [
    "#self checking and paths observation\n",
    "tr_clean_paths_list = get_clean_data_paths(train1_path)\n",
    "check_data_paths(tr_clean_paths_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input list length = 150\n",
      "data/val/val/clean/1084\n",
      "data/val/val/clean/1110\n",
      "data/val/val/clean/1152\n",
      "data/val/val/clean/1154\n",
      "data/val/val/clean/1166\n",
      "data/val/val/clean/1421\n",
      "data/val/val/clean/149\n",
      "data/val/val/clean/1572\n",
      "data/val/val/clean/1593\n",
      "data/val/val/clean/1680\n",
      "data/val/val/clean/1685\n"
     ]
    }
   ],
   "source": [
    "#self checking and paths observation\n",
    "val_clean_paths_list = get_clean_data_paths(val_path)\n",
    "check_data_paths(val_clean_paths_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load, transpose and check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_clean_data_paths(clean_data_paths: list):\n",
    "    \"\"\"\n",
    "    Loading numpy arrays situated on input list paths.\n",
    "    input: paths to clean data\n",
    "    output: loaded clean and noisy data to lists of np.ndarrays    \n",
    "    \"\"\"\n",
    "    clean_data_list = []\n",
    "    noisy_data_list = []\n",
    "\n",
    "    #scans every dir path\n",
    "    for path in clean_data_paths:\n",
    "        #scans every file in current dir\n",
    "        with os.scandir(path) as entries:\n",
    "            for entry in entries:\n",
    "                if entry.is_file():\n",
    "                    clean_path = entry.path\n",
    "                    noisy_path = entry.path.replace('clean', 'noisy',1)\n",
    "\n",
    "                    clean_data_list.append(np.load(clean_path).T)\n",
    "                    noisy_data_list.append(np.load(noisy_path).T)\n",
    "    return clean_data_list, noisy_data_list\n",
    "\n",
    "def check_loaded_data(data1_list, data2_list, check_part=0.1, check_shapes=True, print_shapes=False, check_data=False):\n",
    "    \"\"\"\n",
    "    Help checking loaded data: if data from 2 lists has same shape and doesn't contain nans, zeros only and so on\n",
    "    \"\"\"\n",
    "    \n",
    "    cnt2check = int(max(1, len(data1_list)*check_part))\n",
    "    samples2check = np.random.choice(range(len(data1_list)), cnt2check, replace=False)\n",
    "    \n",
    "    different_shape = False\n",
    "    for index in samples2check:\n",
    "        if data1_list[index].shape != data2_list[index].shape:\n",
    "            different_shape = True\n",
    "            print(f'Difference in shape is detected!'\n",
    "                 f'\\t{data1_list[index].shape} vs {data2_list[index].shape}')\n",
    "            break\n",
    "        if print_shapes:\n",
    "            print(data1_list[index].shape)\n",
    "    \n",
    "    if check_data:\n",
    "        for index in samples2check:\n",
    "            print(f'mean1 = {np.mean(data1_list[index]):5.3}, std1 = {np.std(data1_list[index]):5.3}\\t'\n",
    "                  f'mean2 = {np.mean(data2_list[index]):5.3}, std2 = {np.std(data2_list[index]):5.3}')\n",
    "        \n",
    "def get_data_statistics(data):\n",
    "    \"\"\"\n",
    "    Prints some data statistics and plots histogram of data lengths\n",
    "    \"\"\"\n",
    "    dataLens = []\n",
    "    for d in data:\n",
    "        dataLens.append(d.shape[1])\n",
    "    dataLens = np.array(dataLens)\n",
    "    maxLen = np.max(dataLens)\n",
    "    minLen = np.min(dataLens)\n",
    "    meanLen = np.mean(dataLens)\n",
    "    stdLen = np.std(dataLens)\n",
    "    print(f'Data length params: min={minLen}, max={maxLen}, mean={meanLen}, std={stdLen}')\n",
    "    plt.figure(figsize=(10,10))\n",
    "    sns.histplot(data=dataLens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#self checking and data observation\n",
    "train_clean_data, train_noisy_data = get_data_from_clean_data_paths(tr_clean_paths_list[:])\n",
    "check_loaded_data(train_clean_data, train_noisy_data, print_shapes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, (80, 966))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_clean_data), train_clean_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_clean_data, val_noisy_data = get_data_from_clean_data_paths(val_clean_paths_list[:])\n",
    "check_loaded_data(val_clean_data, val_noisy_data, print_shapes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data length params: min=52, max=1374, mean=758.94225, std=246.37345585162137\n",
      "Data length params: min=113, max=1226, mean=755.392, std=245.4581539407481\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_data_statistics(train_clean_data)\n",
    "get_data_statistics(val_clean_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing training in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size for training process\n",
    "train_batch_size = 64\n",
    "# batch size for evaluation process\n",
    "dev_batch_size = 64\n",
    "# part of train data for progress estimation\n",
    "dev_part = 0.1\n",
    "# max number of epochs\n",
    "nEpochs = 100\n",
    "# starting learning rate\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will use PyTorch functionality for batch construction:\n",
    "  - custom Dataset class to store data with different sizes,\n",
    "  - customized collate_fn to form batches of different shape elements in DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectionDS(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class.\n",
    "    Maintains\n",
    "        data - clean and noisy data\n",
    "        targets - target values for classification (0 - clean, 1 - noisy)\n",
    "    \"\"\"\n",
    "    def __init__(self, clean, noisy):\n",
    "        #initialize class object\n",
    "        \n",
    "        #concatenate clean and noisy data lists\n",
    "        self.data = clean + noisy\n",
    "        #generate corresponding targets\n",
    "        self.targets = [0 for i in range(len(clean))] + [1 for i in range(len(noisy))]\n",
    "        \n",
    "    def __len__(self):\n",
    "        #standard interface function for Dataset\n",
    "        if self.data != None:\n",
    "            return len(self.data)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        #standard interface function for Dataset\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        sample = [self.data[idx], self.targets[idx]] #{'mel_data': self.data[idx], 'target': self.targets[idx]}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_function(batch):\n",
    "    \"\"\"\n",
    "    A customization of default PyTorch collate_fn function\n",
    "    Forms batch from items of different size:\n",
    "        looks for min item length and then randomly \n",
    "        cuts parts of min length from each item\n",
    "    \"\"\"\n",
    "    #extract data from input batch\n",
    "    data = [item[0] for item in batch]\n",
    "    targets = [item[1] for item in batch]\n",
    "    \n",
    "    min_len = 100000\n",
    "    for elem in data:\n",
    "        min_len = min(min_len, elem.shape[1])\n",
    "    \n",
    "    #slicing data to size of minimum element\n",
    "    data = [random_cut(elem, min_len) for elem in data]\n",
    "    \n",
    "    return [torch.tensor(data).float(), torch.tensor(targets).float()]\n",
    "        \n",
    "    \n",
    "def random_cut(array, slice_len):\n",
    "    \"\"\"\n",
    "    Help function to randomly cut array through slicing\n",
    "    \"\"\"\n",
    "    start_cut_range = array.shape[1] - slice_len\n",
    "    random_start = np.random.randint(0, start_cut_range+1)\n",
    "\n",
    "    return array[:, random_start: random_start+slice_len]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coherent_list_shuffle(list1, list2):\n",
    "    \"\"\"\n",
    "    Shuffles 2 lists of the same length in coherent manner\n",
    "    and returns them.\n",
    "    It will help us to form random split train data to train and dev datasets\n",
    "    \"\"\"\n",
    "    if len(list1) != len(list2):\n",
    "        print('Error! Lengths of list1 and list2 must be the same!')\n",
    "        return -1\n",
    "    new_order = list(range(len(list1)))\n",
    "    random.shuffle(new_order)\n",
    "    new_list1 = [list1[new_order[i]] for i in new_order]\n",
    "    new_list2 = [list2[new_order[i]] for i in new_order]\n",
    "   \n",
    "    return new_list1, new_list2\n",
    "\n",
    "# l1 = list(range(10))\n",
    "# l2 = list(range(10))\n",
    "# l11,l22 = coherent_list_shuffle(l1, l2)\n",
    "# print(f'{l11}\\n{l22}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_DataLoader(clean_data_list, noisy_data_list, batch_size):\n",
    "    \"\"\"\n",
    "    Returns dataloaders for further training and evaluating\n",
    "    Input:\n",
    "        clean_data_list - list of numpy arrays with clean data\n",
    "        noisy_data_list - list of numpy arrays with noisy data\n",
    "        batch_size - defines batch size\n",
    "    \"\"\"\n",
    "    dataset = DetectionDS(clean_data_list, noisy_data_list)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, \n",
    "                            collate_fn=collate_function, pin_memory=True)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean_data, train_noisy_data = coherent_list_shuffle(train_clean_data, train_noisy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data_length = int(len(train_clean_data)*dev_part)\n",
    "train_data_length = len(train_clean_data) - dev_data_length\n",
    "\n",
    "train_dataloader = get_DataLoader(train_clean_data[:train_data_length], \n",
    "                                  train_noisy_data[:train_data_length],\n",
    "                                  train_batch_size)\n",
    "dev_dataloader = get_DataLoader(train_clean_data[train_data_length:], \n",
    "                                train_noisy_data[train_data_length:],\n",
    "                                dev_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition\n",
    "For noise classification problem we will use 10-convlayer VGG-like CNN with BatchNorm layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryNoiseClassification(nn.Module):\n",
    "    \"\"\"\n",
    "    Model definition.\n",
    "    Layers summary:\n",
    "        There are 5 stages:\n",
    "            1-3 stages consist of 2 Conv1d layers with ReLU -> MaxPool -> BatchNorm.\n",
    "            4th stage consists of 2 Conv1d layers with ReLU -> BatchNorm -> GlobalMaxPool\n",
    "            5th stage consists of 2 Fully-connected layers\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(BinaryNoiseClassification, self).__init__()\n",
    "        #VGG like architecture\n",
    "        self.Conv1_1 = nn.Conv1d(in_channels=80, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.Conv1_2 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.MaxPool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.BatchNorm1 = nn.BatchNorm1d(64)\n",
    "        \n",
    "        self.Conv2_1 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.Conv2_2 = nn.Conv1d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.MaxPool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.BatchNorm2 = nn.BatchNorm1d(128)\n",
    "        \n",
    "        self.Conv3_1 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.Conv3_2 = nn.Conv1d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.MaxPool3 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.BatchNorm3 = nn.BatchNorm1d(256)\n",
    "        \n",
    "        self.Conv4_1 = nn.Conv1d(in_channels=256, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.Conv4_2 = nn.Conv1d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.BatchNorm4 = nn.BatchNorm1d(512)\n",
    "        self.GloMaxPool1 = nn.AdaptiveMaxPool1d(output_size=1)\n",
    "        \n",
    "        self.Linear1 = nn.Linear(in_features=512, out_features=10)\n",
    "        self.Linear2 = nn.Linear(in_features=10, out_features=1)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        #1st stage\n",
    "        x = F.relu(self.Conv1_1(inputs))\n",
    "        x = self.MaxPool1(F.relu(self.Conv1_2(x)))\n",
    "        x = self.BatchNorm1(x)\n",
    "        #2nd stage\n",
    "        x = F.relu(self.Conv2_1(x))\n",
    "        x = self.MaxPool2(F.relu(self.Conv2_2(x)))\n",
    "        x = self.BatchNorm2(x)\n",
    "        #3rd stage\n",
    "        x = F.relu(self.Conv3_1(x))\n",
    "        x = self.MaxPool3(F.relu(self.Conv3_2(x)))\n",
    "        x = self.BatchNorm3(x)\n",
    "        #4th stage\n",
    "        x = F.relu(self.Conv4_1(x))\n",
    "        x = self.GloMaxPool1(F.relu(self.Conv4_2(x)))\n",
    "        x = self.BatchNorm4(x)\n",
    "        #full conv stage\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = F.relu(self.Linear1(x))\n",
    "        x = self.Linear2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryNoiseClassification(\n",
      "  (Conv1_1): Conv1d(80, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (Conv1_2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (MaxPool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (BatchNorm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (Conv2_1): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (Conv2_2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (MaxPool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (BatchNorm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (Conv3_1): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (Conv3_2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (MaxPool3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (BatchNorm3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (Conv4_1): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (Conv4_2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (BatchNorm4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (GloMaxPool1): AdaptiveMaxPool1d(output_size=1)\n",
      "  (Linear1): Linear(in_features=512, out_features=10, bias=True)\n",
      "  (Linear2): Linear(in_features=10, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = BinaryNoiseClassification()\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions for training epoch and evaluating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train(model, dataloader, device, epoch, learning_rate):\n",
    "    \"\"\"\n",
    "    Computes 1 train epoch.\n",
    "    Input: \n",
    "        model - training model, \n",
    "        dataloader - DataLoader with train data,\n",
    "        device - chosen device,\n",
    "        epoch - current epoch number\n",
    "        learning_rate - learning rate for optimizer\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    criterion = nn.BCEWithLogitsLoss(reduction='sum')\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    running_loss = 0.0\n",
    "    handled_samples = 0\n",
    "    handled_samples_report_period = 4000\n",
    "    next_report = handled_samples_report_period\n",
    "    \n",
    "    print(\"Train dataset statistics: \")\n",
    "    for batch_number, data in enumerate(dataloader):\n",
    "        samples, labels = data[0], data[1].unsqueeze_(1)\n",
    "        samples, labels = samples.to(device) , labels.to(device)\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        model.zero_grad()\n",
    "        outputs = model(samples)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        handled_samples += labels.shape[0]\n",
    "        if handled_samples >= next_report:\n",
    "            print(f'epoch = {epoch:4}, handled samples = {handled_samples:5}, '\n",
    "                  f'loss = {running_loss/handled_samples:5.3}')\n",
    "            next_report += handled_samples_report_period\n",
    "    \n",
    "    torch.save(model.state_dict(), f'classifier_epoch{epoch}.pth')\n",
    "    return running_loss/handled_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluate(model, dataloader, device):\n",
    "    \"\"\"\n",
    "    Computes output for data in dataloader and returns loss and accuracy.\n",
    "    Input: \n",
    "        model - trained model, \n",
    "        dataloader - DataLoader with evaluating data,\n",
    "        device - chosen device\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    predictions = None\n",
    "    targets = None\n",
    "    for batch_number, data in enumerate(dataloader):\n",
    "        samples, labels = data[0], data[1].unsqueeze_(1)\n",
    "        samples, labels = samples.to(device) , labels.to(device)\n",
    "\n",
    "        if predictions is None:\n",
    "            predictions = model(samples).cpu().detach().numpy()\n",
    "            targets = labels.cpu().detach().numpy()\n",
    "        else:        \n",
    "            predictions = np.concatenate((predictions, model(samples).cpu().detach().numpy()), axis=0)\n",
    "            targets = np.concatenate((targets, labels.cpu().detach().numpy()), axis=0)\n",
    "    \n",
    "    accuracy = binary_acc(predictions, targets)\n",
    "    loss = criterion(torch.tensor(predictions), torch.tensor(targets)).item()\n",
    "    print(f\"\\nEval dataset statistics: \"\n",
    "          f\"eval_loss = {loss:5.3}, eval_accuracy = {accuracy:5.3}%\\n\")\n",
    "    \n",
    "    return loss, accuracy\n",
    "\n",
    "def binary_acc(y_pred, y_test):\n",
    "    \"\"\"\n",
    "    Calculates objective metric: Accuracy\n",
    "    Input: \n",
    "        y_pred - model predictions, \n",
    "        y_test - ground truth\n",
    "    \"\"\"\n",
    "    y_test, y_pred = torch.from_numpy(y_test).float(), torch.from_numpy(y_pred).float()\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float().item()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = np.round(acc*100, 2)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset statistics: \n",
      "epoch =    1, handled samples =  4032, loss = 0.251\n",
      "epoch =    1, handled samples =  8000, loss = 0.222\n",
      "epoch =    1, handled samples = 12032, loss = 0.207\n",
      "epoch =    1, handled samples = 16000, loss = 0.201\n",
      "epoch =    1, handled samples = 20032, loss = 0.196\n",
      "\n",
      "Eval dataset statistics: eval_loss = 0.171, eval_accuracy =  94.0%\n",
      "\n",
      "Train dataset statistics: \n",
      "epoch =    2, handled samples =  4032, loss = 0.184\n",
      "epoch =    2, handled samples =  8000, loss = 0.175\n",
      "epoch =    2, handled samples = 12032, loss =  0.17\n",
      "epoch =    2, handled samples = 16000, loss = 0.168\n",
      "epoch =    2, handled samples = 20032, loss = 0.161\n",
      "\n",
      "Eval dataset statistics: eval_loss =  0.17, eval_accuracy =  93.7%\n",
      "\n",
      "Train dataset statistics: \n",
      "epoch =    3, handled samples =  4032, loss = 0.151\n",
      "epoch =    3, handled samples =  8000, loss = 0.148\n",
      "epoch =    3, handled samples = 12032, loss = 0.144\n",
      "epoch =    3, handled samples = 16000, loss = 0.141\n",
      "epoch =    3, handled samples = 20032, loss = 0.143\n",
      "\n",
      "Eval dataset statistics: eval_loss = 0.159, eval_accuracy =  95.0%\n",
      "\n",
      "Train dataset statistics: \n",
      "epoch =    4, handled samples =  4032, loss = 0.135\n",
      "epoch =    4, handled samples =  8000, loss = 0.132\n",
      "epoch =    4, handled samples = 12032, loss = 0.132\n",
      "epoch =    4, handled samples = 16000, loss = 0.128\n",
      "epoch =    4, handled samples = 20032, loss = 0.128\n",
      "\n",
      "Eval dataset statistics: eval_loss = 0.117, eval_accuracy =  95.9%\n",
      "\n",
      "Train dataset statistics: \n",
      "epoch =    5, handled samples =  4032, loss = 0.119\n",
      "epoch =    5, handled samples =  8000, loss = 0.126\n",
      "epoch =    5, handled samples = 12032, loss = 0.125\n",
      "epoch =    5, handled samples = 16000, loss = 0.119\n",
      "epoch =    5, handled samples = 20032, loss =  0.12\n",
      "\n",
      "Eval dataset statistics: eval_loss = 0.105, eval_accuracy =  96.1%\n",
      "\n",
      "Train dataset statistics: \n",
      "epoch =    6, handled samples =  4032, loss = 0.128\n",
      "epoch =    6, handled samples =  8000, loss = 0.123\n",
      "epoch =    6, handled samples = 12032, loss = 0.114\n",
      "epoch =    6, handled samples = 16000, loss = 0.115\n",
      "epoch =    6, handled samples = 20032, loss = 0.116\n",
      "\n",
      "Eval dataset statistics: eval_loss = 0.104, eval_accuracy =  96.6%\n",
      "\n",
      "Train dataset statistics: \n",
      "epoch =    7, handled samples =  4032, loss = 0.102\n",
      "epoch =    7, handled samples =  8000, loss = 0.105\n",
      "epoch =    7, handled samples = 12032, loss = 0.0997\n",
      "epoch =    7, handled samples = 16000, loss = 0.106\n",
      "epoch =    7, handled samples = 20032, loss = 0.107\n",
      "\n",
      "Eval dataset statistics: eval_loss = 0.144, eval_accuracy =  95.0%\n",
      "\n",
      "Train dataset statistics: \n",
      "epoch =    8, handled samples =  4032, loss = 0.101\n",
      "epoch =    8, handled samples =  8000, loss = 0.103\n",
      "epoch =    8, handled samples = 12032, loss = 0.102\n",
      "epoch =    8, handled samples = 16000, loss = 0.105\n",
      "epoch =    8, handled samples = 20032, loss = 0.106\n",
      "\n",
      "Eval dataset statistics: eval_loss = 0.103, eval_accuracy =  96.1%\n",
      "\n",
      "Train dataset statistics: \n",
      "epoch =    9, handled samples =  4032, loss = 0.0962\n",
      "epoch =    9, handled samples =  8000, loss = 0.096\n",
      "epoch =    9, handled samples = 12032, loss = 0.0929\n",
      "epoch =    9, handled samples = 16000, loss = 0.0932\n",
      "epoch =    9, handled samples = 20032, loss = 0.0944\n",
      "\n",
      "Eval dataset statistics: eval_loss = 0.0886, eval_accuracy =  96.8%\n",
      "\n",
      "Train dataset statistics: \n",
      "epoch =   10, handled samples =  4032, loss = 0.0935\n",
      "epoch =   10, handled samples =  8000, loss = 0.0924\n",
      "epoch =   10, handled samples = 12032, loss = 0.097\n",
      "epoch =   10, handled samples = 16000, loss = 0.0963\n",
      "epoch =   10, handled samples = 20032, loss = 0.0963\n",
      "\n",
      "Eval dataset statistics: eval_loss = 0.0972, eval_accuracy =  96.6%\n",
      "\n",
      "Train dataset statistics: \n",
      "epoch =   11, handled samples =  4032, loss = 0.098\n",
      "epoch =   11, handled samples =  8000, loss = 0.0927\n",
      "epoch =   11, handled samples = 12032, loss = 0.0905\n",
      "epoch =   11, handled samples = 16000, loss = 0.0902\n",
      "epoch =   11, handled samples = 20032, loss = 0.0893\n",
      "\n",
      "Eval dataset statistics: eval_loss = 0.0948, eval_accuracy =  97.0%\n",
      "\n",
      "Train dataset statistics: \n",
      "epoch =   12, handled samples =  4032, loss = 0.0866\n",
      "epoch =   12, handled samples =  8000, loss = 0.0893\n",
      "epoch =   12, handled samples = 12032, loss = 0.0892\n",
      "epoch =   12, handled samples = 16000, loss = 0.0869\n",
      "epoch =   12, handled samples = 20032, loss = 0.0874\n",
      "\n",
      "Eval dataset statistics: eval_loss = 0.126, eval_accuracy =  94.9%\n",
      "\n",
      "Train dataset statistics: \n",
      "epoch =   13, handled samples =  4032, loss = 0.0805\n",
      "epoch =   13, handled samples =  8000, loss = 0.0916\n",
      "epoch =   13, handled samples = 12032, loss = 0.0884\n",
      "epoch =   13, handled samples = 16000, loss = 0.0881\n",
      "epoch =   13, handled samples = 20032, loss = 0.0858\n",
      "\n",
      "Eval dataset statistics: eval_loss = 0.101, eval_accuracy =  96.5%\n",
      "\n",
      "Train dataset statistics: \n",
      "epoch =   14, handled samples =  4032, loss = 0.0768\n",
      "epoch =   14, handled samples =  8000, loss = 0.0784\n",
      "epoch =   14, handled samples = 12032, loss = 0.0807\n",
      "epoch =   14, handled samples = 16000, loss = 0.082\n",
      "epoch =   14, handled samples = 20032, loss = 0.0857\n",
      "\n",
      "Eval dataset statistics: eval_loss = 0.0706, eval_accuracy =  97.5%\n",
      "\n",
      "Train dataset statistics: \n",
      "epoch =   15, handled samples =  4032, loss = 0.0812\n",
      "epoch =   15, handled samples =  8000, loss = 0.0798\n",
      "epoch =   15, handled samples = 12032, loss = 0.0787\n",
      "epoch =   15, handled samples = 16000, loss = 0.0808\n",
      "epoch =   15, handled samples = 20032, loss = 0.0781\n",
      "\n",
      "Eval dataset statistics: eval_loss = 0.0655, eval_accuracy =  97.8%\n",
      "\n",
      "Train dataset statistics: \n",
      "epoch =   16, handled samples =  4032, loss = 0.0854\n",
      "epoch =   16, handled samples =  8000, loss = 0.0817\n",
      "epoch =   16, handled samples = 12032, loss = 0.0787\n",
      "epoch =   16, handled samples = 16000, loss = 0.0781\n",
      "epoch =   16, handled samples = 20032, loss = 0.0793\n",
      "\n",
      "Eval dataset statistics: eval_loss = 0.0704, eval_accuracy =  97.5%\n",
      "\n",
      "Train dataset statistics: \n",
      "epoch =   17, handled samples =  4032, loss = 0.0794\n",
      "epoch =   17, handled samples =  8000, loss = 0.0819\n",
      "epoch =   17, handled samples = 12032, loss = 0.0834\n",
      "epoch =   17, handled samples = 16000, loss = 0.078\n",
      "epoch =   17, handled samples = 20032, loss = 0.0792\n",
      "\n",
      "Eval dataset statistics: eval_loss = 0.0739, eval_accuracy =  97.5%\n",
      "\n",
      "Train dataset statistics: \n",
      "epoch =   18, handled samples =  4032, loss = 0.0768\n",
      "epoch =   18, handled samples =  8000, loss = 0.074\n",
      "epoch =   18, handled samples = 12032, loss = 0.0731\n",
      "epoch =   18, handled samples = 16000, loss = 0.0746\n",
      "epoch =   18, handled samples = 20032, loss = 0.0762\n",
      "\n",
      "Eval dataset statistics: eval_loss = 0.082, eval_accuracy =  97.5%\n",
      "\n",
      "Model stops improving on dev dataset!\n",
      "It is early stopping!\n",
      "Best model is saved as 'classifier_epoch15.pth'\n"
     ]
    }
   ],
   "source": [
    "cur_learning_rate = learning_rate\n",
    "best_model_epoch = 0\n",
    "no_improve_epochs = 0\n",
    "no_improve_epochs_to_stop = 3\n",
    "best_dev_acuracy = 0.0\n",
    "\n",
    "train_losses = []\n",
    "dev_losses = []\n",
    "dev_accuracies = []\n",
    "\n",
    "for epoch in range(1, nEpochs+1):\n",
    "    train_loss = Train(model, train_dataloader, device, epoch, cur_learning_rate)\n",
    "    dev_loss, dev_accuracy = Evaluate(model, dev_dataloader, device)\n",
    "    train_losses.append(train_loss)\n",
    "    dev_losses.append(dev_loss)\n",
    "    dev_accuracies.append(dev_accuracy)\n",
    "    \n",
    "    if dev_accuracy > best_dev_acuracy:\n",
    "        best_dev_acuracy = dev_accuracy\n",
    "        best_model_epoch = epoch\n",
    "        no_improve_epochs = 0\n",
    "    else:\n",
    "        no_improve_epochs += 1\n",
    "        if no_improve_epochs == no_improve_epochs_to_stop:\n",
    "            print(f'Model stops improving on dev dataset!\\n'\n",
    "                  f'It is early stopping!\\n'\n",
    "                  f\"Best model is saved as 'classifier_epoch{best_model_epoch}.pth'\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier evaluation\n",
    "Loading best trained model and compute its loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_classification_model = BinaryNoiseClassification()\n",
    "model_state_dict = torch.load(f'classifier_epoch{best_model_epoch}.pth')\n",
    "loaded_classification_model.load_state_dict(model_state_dict)\n",
    "loaded_classification_model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = get_DataLoader(val_clean_data, val_noisy_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval dataset statistics: eval_loss = 0.0544, eval_accuracy =  98.3%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_accuracy = Evaluate(loaded_classification_model, val_dataloader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
